{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "\r\n",
    "class NB():\r\n",
    "    def __init__(self):\r\n",
    "        self.priors = {}\r\n",
    "        self.likelihoods = {}\r\n",
    "        self.classes = []\r\n",
    "\r\n",
    "    def fit(self, X, y):\r\n",
    "        X = pd.DataFrame(X)\r\n",
    "        self.classes = np.unique(y)\r\n",
    "        for outcome in self.classes:\r\n",
    "            self.priors[outcome] = sum(y == outcome) / len(y)\r\n",
    "        k = len(X.columns)\r\n",
    "        for feature in X.columns:\r\n",
    "            self.likelihoods[feature] = {}\r\n",
    "            for outcome in self.classes:\r\n",
    "                outcome_count = sum(y == outcome)\r\n",
    "                likelihood = X[feature][y[y == outcome].index.values.tolist()].value_counts().to_dict()\r\n",
    "                for feat_val, count in likelihood.items():\r\n",
    "                    if feat_val not in self.likelihoods[feature]:\r\n",
    "                        self.likelihoods[feature][feat_val] = {}\r\n",
    "                    self.likelihoods[feature][feat_val][outcome] = (count + 1) / (outcome_count + k)\r\n",
    "        return self\r\n",
    "\r\n",
    "    def predict(self, data):\r\n",
    "        results = []\r\n",
    "        data = pd.DataFrame(data)\r\n",
    "        X = np.array(data)\r\n",
    "\r\n",
    "        for sample in X:\r\n",
    "            probs = {}\r\n",
    "            for outcome in self.classes:\r\n",
    "                prob = np.log(self.priors[outcome])\r\n",
    "                for feature, feat_val in zip(data.columns, sample):\r\n",
    "                    if feat_val not in self.likelihoods[feature]:\r\n",
    "                        prob += np.log(1/(len(self.likelihoods[feature])+1))\r\n",
    "                    elif outcome not in self.likelihoods[feature][feat_val]:\r\n",
    "                        prob += np.log(self.priors[outcome] / len(self.likelihoods[feature]))\r\n",
    "                    else:\r\n",
    "                        prob += np.log(self.likelihoods[feature][feat_val][outcome])\r\n",
    "                probs[outcome] = prob\r\n",
    "            results.append(max(probs, key=lambda x: probs[x]))\r\n",
    "        return results\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\r\n",
    "\r\n",
    "X, y = df.drop('Iris-setosa', 1), df['Iris-setosa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "\r\n",
    "results = GaussianNB().fit(X_train, y_train).predict(X_test)\r\n",
    "\r\n",
    "accuracy_score(y_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = NB().fit(X_train, y_train)\r\n",
    "\r\n",
    "results = nb.predict(X_test)\r\n",
    "\r\n",
    "accuracy_score(y_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}